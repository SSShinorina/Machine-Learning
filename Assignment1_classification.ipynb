{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Assingment  1 of Machine Learning Course 5DV194! \n",
    "The task is to create a classifier for cancer diagnose (malignant or benign)\n",
    "#### Deadline of Assignment 1:\n",
    "28 Feb. 2022 (17:00 Stockholm time)\n",
    "\n",
    "#### Goal \n",
    "To get familar with (installation and usage) Jupyter notebook and machine learning library Sklearn (https://scikit-learn.org/stable/) by applying four different classification algorithms (KNN, Logistic Regression, SVM, Decision Tree) on the same task.  Additionally, you also call functions for data scaling, regularization, and kernel function.\n",
    "#### Dataset\n",
    "Breast Cancer Wisconsin (Diagnostic) Database.\n",
    "https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)\n",
    "\n",
    " \n",
    "\n",
    "#### Grading (200 points)\n",
    "##### 100 points \n",
    "Follow this jupyter notebook file below, you will find some Tasks (answer by coding) and Questions(answer by text).\n",
    "##### 40 points \n",
    "In SVM algorithm, you will be asked to implement two kernel functions and apply them in your SVM model.  \n",
    "##### 60 points (report)\n",
    "More instruction in report file \"Report Template for Assignment-3 (5DV194)\".  \n",
    " \n",
    "\n",
    "Compress report PDF and this jupyter notebook file in a zip file and name the zip file in the format of \"FirstName_LastName_assignment1.zip\", upload to Canvas/Assignments/Assignment-1. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['malignant', 'benign']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "#print the predicton labels (target names)\n",
    "list(cancer.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize our data\n",
    "label_names = cancer['target_names']\n",
    "labels = cancer['target']\n",
    "feature_names = cancer['feature_names']\n",
    "features = cancer['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n",
      "569\n",
      "30\n",
      "569\n"
     ]
    }
   ],
   "source": [
    "# see the data\n",
    "print (label_names) \n",
    "print (len(labels))\n",
    "print (len(feature_names))\n",
    "print (len(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover the data to gain insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-1: print out the number of features the breast cancer dataset has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-2: print out the size of the data set (i.e., number of samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-3: print out the number of instances of malignant and the number of instances of benign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-2197a21ee8e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"malignant benign\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "data=pd.Series(df['target'].value_counts(ascending))\n",
    "data.index=\"malignant benign\".split()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiny practice to prepare training and test data for algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will split dataset into training dataset (x) and testing dataset (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import train_test_split from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split our data with traing data test_size=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question（no coding need）: Is above split of training/testing is random? How to make the training and test data fixed, so you can reproduce your results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-4c505918f0c7>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-4c505918f0c7>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    answer:\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we just finish some warming excercises, in the following, we will train four different classifier and use them to do cancer prediction respectively.\n",
    "\n",
    "## General Learning Process\n",
    "#### 1. load the data and prepare the data\n",
    "#### 2. Implement an algorithm\n",
    "#### 3. Train the algorithm, verify accuracy, and optimize.\n",
    "#### 4. Predict on test data.\n",
    "#### 5. Output the prediction performance\n",
    "\n",
    "Note that in this assigment, to run the tasks, you are not requied to implment the classifiction algorithms, which are already implemented in backend in sklearn library. It is your responsibility to explore which function can be used and should be used to implement the Tasks below.  Furthermore, feel free to explore new functions though not mandatory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm1: KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### okay, now let's asume we start from scratch to use KNN for this classification task. \n",
    "#### Task-4: load cancer data as you did in above warming excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-5: split data into training data and test data, keep training/test size as default, but specify a fixed value for random_state yourself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.3,train_size=0.7,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select an algorithm\n",
    "#### Train KNN model using KNeighborsClassifier in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We predict cancer on the test data using the trained KNN and output the prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0 1 0 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 0\n",
      " 1 0 1 1 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 1 0 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "prediction = knn.predict(X_test)\n",
    "print (prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we output the accuracies of the trained KNN model on training data and test data respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9371859296482412\n",
      "0.9298245614035088\n"
     ]
    }
   ],
   "source": [
    "print (knn.score(X_train, y_train))\n",
    "print (knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-6: round down the floats to two decimals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94\n",
      "0.93\n"
     ]
    }
   ],
   "source": [
    "train_decimal=knn.score(X_train, y_train)\n",
    "print(round(train_decimal,2))\n",
    "test_decimal=knn.score(X_test, y_test)\n",
    "print(round(test_decimal,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we are going to do some optimization, to explore the best N value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task-7: print out the value of N in your above trianed KNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9695359714832658\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print(math.sqrt(round(train_decimal,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task-8: try different N (e.g., [1,10]), and print out the accuracy when N is applied with different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93\n",
      "0.94\n",
      "0.93\n",
      "0.94\n",
      "0.93\n",
      "0.94\n",
      "0.93\n",
      "0.94\n",
      "0.93\n",
      "0.94\n",
      "0.93\n",
      "0.94\n",
      "0.93\n",
      "0.94\n",
      "0.93\n",
      "0.94\n",
      "0.93\n",
      "0.94\n"
     ]
    }
   ],
   "source": [
    "neighbors_settings = range(1, 10)\n",
    "for n_neighbors in neighbors_settings:\n",
    "    knn1 = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn1.fit(X_train, y_train)\n",
    "    train_decimal=knn.score(X_train, y_train)\n",
    "    test_decimal=knn.score(X_test, y_test)\n",
    "    print(round(test_decimal,2))\n",
    "    print(round(train_decimal,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm2: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task-9: Split the data into training data and test data as you did above, this time try to not copy but write the code yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.3,train_size=0.7,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task-10: Train logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below we predict cancer on the test data using the trained logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task-11: print out the accuracies of the trained  logistic regression model on training data and test data respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94\n",
      "0.97\n"
     ]
    }
   ],
   "source": [
    "print (round(log_reg.score(X_train, y_train),2))\n",
    "print (round(log_reg.score(X_test, y_test),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization (Regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-12: Train a logistic regression model by modifying the regularization parameter C to different values (e.g., 100), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "for i,C in enumerate((100, 1, 0.01)):\n",
    "    log_reg1 = LogisticRegression(C=C, penalty='l1', solver='liblinear')\n",
    "    log_reg1.fit(X_train, y_train)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-13: print the corresponding training and testing accuracy to see the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n",
      "0.98\n",
      "0.95\n",
      "0.96\n",
      "0.91\n",
      "0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "for i,C in enumerate((100, 1, 0.01)):\n",
    "    log_reg1 = LogisticRegression(C=C, penalty='l1', solver='liblinear')\n",
    "    log_reg1.fit(X_train, y_train)\n",
    "    print (round(log_reg1.score(X_train, y_train),2))\n",
    "    print (round(log_reg1.score(X_test, y_test),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-14: Lower the regularization parameter C as 0.01, and print out the corresponding training and testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91\n",
      "0.95\n"
     ]
    }
   ],
   "source": [
    "log_reg2 = LogisticRegression(C=0.01, penalty='l1', solver='liblinear')\n",
    "log_reg2.fit(X_train, y_train)\n",
    "print (round(log_reg2.score(X_train, y_train),2))\n",
    "print (round(log_reg2.score(X_test, y_test),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm3: SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are loading data and splitting data into training data and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=0)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_scaled = MinMaxScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task-15:  train a SVM model using SVC model in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "#codes to train a SVM model\n",
    "\n",
    "svm=SVC()\n",
    "svm.fit(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We predict cancer on the test data using the trained SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task-16: print out the accuracy of the training and prediction respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97\n"
     ]
    }
   ],
   "source": [
    "print (round(svm.score(X_train,y_train),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Optimization by using kernel function\n",
    "#### Task-17: print the name of the default kernel function in above model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Okay, now we will have a little bit harder nut to crack :-) \n",
    "#### Task-18:  implement two kernel functions (linear and Gaussian) on your own and evaluate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel=linear\n",
    "def my_kernel_linear(xi,xj):\n",
    "    return np.dot(xi,xj.T)\n",
    "    \n",
    "    # write a linear kernel function here\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel=Gaussian = RBF\n",
    "def my_kernel_gaussian(xi,xj):\n",
    "    z=np.dot(((xi-xj)),(xi-xj).T)\n",
    "    return (1/np.sqrt(2*np.pi))*np.exp(-0.5*z**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, let's replace the default kernel function with your kernel.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel=<function my_kernel_linear at 0x000002A25DE33A60>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_linear_kernel = SVC(kernel=my_kernel_linear)\n",
    "svm_linear_kernel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task-19: print out the accuracy  of SVM models with kernel function my_kernel_linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9802197802197802\n"
     ]
    }
   ],
   "source": [
    "print (svm_linear_kernel.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below, we replace the default kernel function with the gaussian kernel you wrote.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel=<function my_kernel_gaussian at 0x000002A25DE4E430>)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_gaussian_kernel = SVC(kernel=my_kernel_gaussian)\n",
    "svm_gaussian_kernel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-20: print out the accuracy of SVM models with kernel function my_kernel_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6373626373626373\n"
     ]
    }
   ],
   "source": [
    "print (svm_gaussian_kernel.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm4:  Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Okay, after above repetitive practices.  I would let you complete the whole training and testing process by yourself for decision tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  get data, split into traing data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task-21: train a Decision Tree model using DecisionTreeClassifier in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-22: predict cancer on the test data using the trained Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 1 1 1 0 0 1 1 1 0 1 1 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 0 0 0 1 1 0 1 1 1 1 0 1\n",
      " 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1\n",
      " 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 1 1 1\n",
      " 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "prediction = dtc.predict(X_test)\n",
    "print (prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task-23: output the accuracies of the trained  logistic regression model on training data and test data respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.91\n"
     ]
    }
   ],
   "source": [
    "print (round(dtc.score(X_train, y_train),2))\n",
    "print (round(dtc.score(X_test, y_test),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-24: output the feature importances in this decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.00800332 0.         0.00800332 0.         0.\n",
      " 0.         0.05837837 0.         0.         0.00258569 0.\n",
      " 0.         0.03392508 0.00711407 0.         0.         0.\n",
      " 0.         0.04200904 0.0356893  0.03055815 0.70826499 0.01296678\n",
      " 0.         0.         0.01042735 0.04207453 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "importance = dtc.feature_importances_\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-25: using matplotlib.pyplot to visualize feature importance value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Congratualtions if you run through above!  \n",
    "#### If you are already familar with the training process using Sklearn, feel free to try other settings to improve the accuracy.\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
